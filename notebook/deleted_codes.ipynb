{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba40e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import meteostat as ms\n",
    "\n",
    "# Specify location and time range\n",
    "POINT = ms.Point(38.8512, -77.0402, 4)   # Try with your location\n",
    "START = datetime(2013, 1, 1)\n",
    "END = datetime(2013, 3, 31, 23, 59)\n",
    "\n",
    "\n",
    "# Get nearby weather stations\n",
    "stations = ms.stations.nearby(POINT, limit=4)\n",
    "\n",
    "# Get daily data & perform interpolation\n",
    "ts = ms.hourly(stations, START, END)\n",
    "df = ms.interpolate(ts, POINT).fetch()\n",
    "\n",
    "\n",
    "# 4. Feature Engineering : Création de tes variables spécifiques\n",
    "\n",
    "# Création du DataFrame propre\n",
    "df_weather = pd.DataFrame()\n",
    "df_weather['dteday'] = df.index\n",
    "df_weather['hr'] = df.index.hour\n",
    "df_weather['temp'] = df['temp'].values # Température en °C\n",
    "df_weather['hum'] = df['rhum'].values # Humidité relative\n",
    "df_weather['windspeed'] = df['wspd'].values # Vitesse du vent en km/h\n",
    "\n",
    "# Calcul approximatif de la température ressentie (ATemp)\n",
    "# Formule simple basée sur Température et Vent (Wind Chill) ou Humidité\n",
    "# Ici on utilise une approximation standard pour l'exemple\n",
    "# atemp = T + 0.33 * e - 0.7 * v - 4.0 (Formule simplifiée, sinon Heat Index)\n",
    "# Pour faire simple ici, on garde une corrélation forte avec la Temp\n",
    "df_weather['atemp'] = df['temp'].values # À affiner si besoin de formule précise\n",
    "\n",
    "# 5. Le Challenge : Mapper les codes météo (COCO) vers ton échelle 1-4\n",
    "# Meteostat utilise les codes COCO : https://dev.meteostat.net/formats.html#weather-condition-codes\n",
    "# 1-6: Clear/Cloudy | 7-9: Mist/Fog | 10-16: Rain | 17-27: Storm/Snow\n",
    "\n",
    "def map_weathersit(coco_code):\n",
    "    if pd.isna(coco_code):\n",
    "        return 2 # Valeur par défaut si manquant (souvent nuageux)\n",
    "    \n",
    "    code = int(coco_code)\n",
    "    \n",
    "    # Catégorie 1: Clear, Few clouds, Partly cloudy\n",
    "    if code in [1, 2, 3]: \n",
    "        return 1\n",
    "    # Catégorie 2: Mist + Cloudy\n",
    "    elif code in [4, 5, 6, 7, 8, 9]: \n",
    "        return 2\n",
    "    # Catégorie 3: Light Snow, Light Rain\n",
    "    elif code in [10, 11, 12, 13, 14, 15, 16, 17, 18]: \n",
    "        return 3\n",
    "    # Catégorie 4: Heavy Rain, Ice, Thunderstorm\n",
    "    elif code in [19, 20, 21, 22, 23, 24, 25, 26, 27]: \n",
    "        return 4\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "#df_weather['weathersit'] = df['coco'].apply(map_weathersit)\n",
    "\n",
    "# Vérification des données\n",
    "print(\"\\nAperçu des données :\")\n",
    "print(df_weather[['dteday', 'temp', 'hum']].head())\n",
    "\n",
    "# print(\"\\nDistribution des Weathersit :\")\n",
    "# print(df_weather['weathersit'].value_counts().sort_index())\n",
    "\n",
    "# 6. Sauvegarde\n",
    "output_file = 'washington_weather_2013_Q1.csv'\n",
    "df_weather.to_csv(output_file, index=False)\n",
    "print(f\"\\nFichier sauvegardé avec succès : {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot line chart including average, minimum and maximum temperature\n",
    "#df.plot(y=[ms.Parameter.TEMP, ms.Parameter.TMIN, ms.Parameter.TMAX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"1-problem\"></a>\n",
    "## 1. Explication du problème de machine learning\n",
    "> *Description du problème que vous souhaitez résoudre.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"2-data-presentation\"></a>\n",
    "## 2. Présentation du jeu de données\n",
    "> *Origine, contexte et description des données.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"3-eda\"></a>\n",
    "## 3. Exploration du jeu de données\n",
    "> *Analyse descriptive, statistiques, visualisations.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"4-cleaning\"></a>\n",
    "## 4. Data cleaning et imputation de données manquantes\n",
    "> *Nettoyage et gestion des NA si nécessaire.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"5-feature-engineering\"></a>\n",
    "## 5. Feature Engineering\n",
    "> *Explication de la démarche et des variables créées (lags, moyennes mobiles, date, etc.).*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"6-preprocessing\"></a>\n",
    "## 6. Préparation des données pour être fournies à un modèle ML/DL\n",
    "> *Normalisation, Split Train/Test/Val, formatage des séquences.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"7-model-selection\"></a>\n",
    "## 7. Sélection de différents modèles\n",
    "> *Critères de sélection, métriques choisies (RMSE, MAE...), baselines.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"8-evaluation\"></a>\n",
    "## 8. Évaluation de la performance des modèles\n",
    "> *Recherche d'hyperparamètres, contrôle de l’overfitting, comparaison sur différents horizons.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"9-discussion\"></a>\n",
    "## 9. Discussion autour de la performance des modèles\n",
    "> *Analyse critique des résultats.*\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"10-conclusion\"></a>\n",
    "## 10. Synthèse et conclusions\n",
    "> *Résumé et pistes d’améliorations envisagées.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef0c9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09dfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11886eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
